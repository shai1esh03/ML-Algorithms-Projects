{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvpyI0E7SpNT"
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is an ensemble of Decision Trees. With a few exceptions, a `RandomForestClassifier` has all the hyperparameters of a `DecisionTreeClassifier` (to control how trees are grown), plus all the hyperparameters of a `BaggingClassifier` to control the ensemble itself.\n",
    "\n",
    "The Random Forest algorithm introduces extra randomness when growing trees; instead of searching for the very best feature when splitting a node, it searches for the best feature among a random subset of features. This results in a greater tree diversity, which (once again) trades a higher bias for a lower variance, generally yielding an overall better model. The following `BaggingClassifier` is roughly equivalent to the previous `RandomForestClassifier`. Run the cell below to visualize a single estimator from a random forest model, using the Iris dataset to classify the data into the appropriate species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1NIbktS4yyfVlE2Y4bXMargRbQgbdWTFh"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7579,
     "status": "ok",
     "timestamp": 1592213046926,
     "user": {
      "displayName": "Andrew Maguire",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjaIpd1sqQPWOc9NJXtyl5fYSonikxEZgshlvloAYk=s64",
      "userId": "13447906511017779027"
     },
     "user_tz": -60
    },
    "id": "z_-6xEUFSpNU",
    "outputId": "75184be3-e99c-4c44-a638-824a9ba0b1e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Model (can also use single decision tree)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "# Train\n",
    "model.fit(iris.data, iris.target)\n",
    "# Extract single tree\n",
    "estimator = model.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = iris.feature_names,\n",
    "                class_names = iris.target_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSnWoCRUSpNY"
   },
   "source": [
    "Notice how each split seperates the data into buckets of similar observations. This is a single tree and a relatively simple classification dataset, but the same method is used in a more complex dataset with greater depth to the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJ2aGPMZB5X8"
   },
   "source": [
    "## Coronavirus\n",
    "Coronavirus disease (COVID-19) is an infectious disease caused by a new virus.\n",
    "The disease causes respiratory illness (like the flu) with symptoms such as a cough, fever, and in more severe cases, difficulty breathing. You can protect yourself by washing your hands frequently, avoiding touching your face, and avoiding close contact (1 meter or 3 feet) with people who are unwell. An outbreak of COVID-19 started in December 2019 and at the time of the creation of this project was continuing to spread throughout the world. Many governments recommended only essential outings to public places and closed most business that do not serve food or sell essential items. An excellent [spatial dashboard](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6) built by Johns Hopkins shows the daily confirmed cases by country. \n",
    "\n",
    "This case study was designed to drive home the important role that data science plays in real-world situations like this pandemic. This case study uses the Random Forest Classifier and a dataset from the South Korean cases of COVID-19 provided on [Kaggle](https://www.kaggle.com/kimjihoo/coronavirusdataset) to encourage research on this important topic. The goal of the case study is to build a Random Forest Classifier to predict the 'state' of the patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PrMkSjBQEMZ"
   },
   "source": [
    "First, please load the needed packages and modules into Python. Next, load the data into a pandas dataframe for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3EhD-LSB5YI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "from pandas_profiling.utils.cache import cache_file\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiJQlTK1SpNd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>global_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>disease</th>\n",
       "      <th>infection_case</th>\n",
       "      <th>infection_order</th>\n",
       "      <th>infected_by</th>\n",
       "      <th>contact_number</th>\n",
       "      <th>symptom_onset_date</th>\n",
       "      <th>confirmed_date</th>\n",
       "      <th>released_date</th>\n",
       "      <th>deceased_date</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>50s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Gangseo-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>30s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jungnang-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000003</td>\n",
       "      <td>6.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>50s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.002000e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000005</td>\n",
       "      <td>9.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>20s</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seongbuk-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  global_num     sex  birth_year  age country province  \\\n",
       "0  1000000001         2.0    male      1964.0  50s   Korea    Seoul   \n",
       "1  1000000002         5.0    male      1987.0  30s   Korea    Seoul   \n",
       "2  1000000003         6.0    male      1964.0  50s   Korea    Seoul   \n",
       "3  1000000004         7.0    male      1991.0  20s   Korea    Seoul   \n",
       "4  1000000005         9.0  female      1992.0  20s   Korea    Seoul   \n",
       "\n",
       "          city disease        infection_case  infection_order   infected_by  \\\n",
       "0   Gangseo-gu     NaN       overseas inflow              1.0           NaN   \n",
       "1  Jungnang-gu     NaN       overseas inflow              1.0           NaN   \n",
       "2    Jongno-gu     NaN  contact with patient              2.0  2.002000e+09   \n",
       "3      Mapo-gu     NaN       overseas inflow              1.0           NaN   \n",
       "4  Seongbuk-gu     NaN  contact with patient              2.0  1.000000e+09   \n",
       "\n",
       "   contact_number symptom_onset_date confirmed_date released_date  \\\n",
       "0            75.0         2020-01-22     2020-01-23    2020-02-05   \n",
       "1            31.0                NaT     2020-01-30    2020-03-02   \n",
       "2            17.0                NaT     2020-01-30    2020-02-19   \n",
       "3             9.0         2020-01-26     2020-01-30    2020-02-15   \n",
       "4             2.0                NaT     2020-01-31    2020-02-24   \n",
       "\n",
       "  deceased_date     state  \n",
       "0           NaT  released  \n",
       "1           NaT  released  \n",
       "2           NaT  released  \n",
       "3           NaT  released  \n",
       "4           NaT  released  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='SouthKoreacoronavirusdataset/PatientInfo.csv'\n",
    "df = pd.read_csv(url, parse_dates=['symptom_onset_date','confirmed_date','released_date','deceased_date'], infer_datetime_format=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2218 entries, 0 to 2217\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   patient_id          2218 non-null   int64         \n",
      " 1   global_num          1314 non-null   float64       \n",
      " 2   sex                 2073 non-null   object        \n",
      " 3   birth_year          1764 non-null   float64       \n",
      " 4   age                 1957 non-null   object        \n",
      " 5   country             2218 non-null   object        \n",
      " 6   province            2218 non-null   object        \n",
      " 7   city                2153 non-null   object        \n",
      " 8   disease             19 non-null     object        \n",
      " 9   infection_case      1163 non-null   object        \n",
      " 10  infection_order     42 non-null     float64       \n",
      " 11  infected_by         469 non-null    float64       \n",
      " 12  contact_number      411 non-null    float64       \n",
      " 13  symptom_onset_date  193 non-null    datetime64[ns]\n",
      " 14  confirmed_date      2077 non-null   datetime64[ns]\n",
      " 15  released_date       223 non-null    datetime64[ns]\n",
      " 16  deceased_date       32 non-null     datetime64[ns]\n",
      " 17  state               2130 non-null   object        \n",
      "dtypes: datetime64[ns](4), float64(5), int64(1), object(8)\n",
      "memory usage: 312.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id            2218\n",
       "global_num            1303\n",
       "sex                      2\n",
       "birth_year              96\n",
       "age                     11\n",
       "country                  4\n",
       "province                17\n",
       "city                   134\n",
       "disease                  1\n",
       "infection_case          16\n",
       "infection_order          6\n",
       "infected_by            206\n",
       "contact_number          72\n",
       "symptom_onset_date      38\n",
       "confirmed_date          45\n",
       "released_date           35\n",
       "deceased_date           16\n",
       "state                    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now= datetime.now()\n",
    "year = now.year\n",
    "df['age'] = year - df['birth_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>global_num</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>disease</th>\n",
       "      <th>infection_case</th>\n",
       "      <th>infection_order</th>\n",
       "      <th>infected_by</th>\n",
       "      <th>contact_number</th>\n",
       "      <th>symptom_onset_date</th>\n",
       "      <th>confirmed_date</th>\n",
       "      <th>released_date</th>\n",
       "      <th>deceased_date</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Gangseo-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jungnang-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000003</td>\n",
       "      <td>6.0</td>\n",
       "      <td>male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.002000e+09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>overseas inflow</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000005</td>\n",
       "      <td>9.0</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Seongbuk-gu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contact with patient</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  global_num     sex   age country province         city disease  \\\n",
       "0  1000000001         2.0    male  56.0   Korea    Seoul   Gangseo-gu     NaN   \n",
       "1  1000000002         5.0    male  33.0   Korea    Seoul  Jungnang-gu     NaN   \n",
       "2  1000000003         6.0    male  56.0   Korea    Seoul    Jongno-gu     NaN   \n",
       "3  1000000004         7.0    male  29.0   Korea    Seoul      Mapo-gu     NaN   \n",
       "4  1000000005         9.0  female  28.0   Korea    Seoul  Seongbuk-gu     NaN   \n",
       "\n",
       "         infection_case  infection_order   infected_by  contact_number  \\\n",
       "0       overseas inflow              1.0           NaN            75.0   \n",
       "1       overseas inflow              1.0           NaN            31.0   \n",
       "2  contact with patient              2.0  2.002000e+09            17.0   \n",
       "3       overseas inflow              1.0           NaN             9.0   \n",
       "4  contact with patient              2.0  1.000000e+09             2.0   \n",
       "\n",
       "  symptom_onset_date confirmed_date released_date deceased_date     state  \n",
       "0         2020-01-22     2020-01-23    2020-02-05           NaT  released  \n",
       "1                NaT     2020-01-30    2020-03-02           NaT  released  \n",
       "2                NaT     2020-01-30    2020-02-19           NaT  released  \n",
       "3         2020-01-26     2020-01-30    2020-02-15           NaT  released  \n",
       "4                NaT     2020-01-31    2020-02-24           NaT  released  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping birth_year as age is calculated\n",
    "df.drop('birth_year', inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <td>2218.0</td>\n",
       "      <td>4.014678e+09</td>\n",
       "      <td>2.192419e+09</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.700000e+09</td>\n",
       "      <td>6.001000e+09</td>\n",
       "      <td>6.004000e+09</td>\n",
       "      <td>7.000000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_num</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>4.664817e+03</td>\n",
       "      <td>2.874044e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.908500e+03</td>\n",
       "      <td>5.210500e+03</td>\n",
       "      <td>7.481500e+03</td>\n",
       "      <td>8.717000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1764.0</td>\n",
       "      <td>4.501134e+01</td>\n",
       "      <td>1.941264e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>4.550000e+01</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>1.040000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infection_order</th>\n",
       "      <td>42.0</td>\n",
       "      <td>2.285714e+00</td>\n",
       "      <td>1.254955e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infected_by</th>\n",
       "      <td>469.0</td>\n",
       "      <td>2.600789e+09</td>\n",
       "      <td>1.570638e+09</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>1.200000e+09</td>\n",
       "      <td>2.000000e+09</td>\n",
       "      <td>4.100000e+09</td>\n",
       "      <td>6.113000e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_number</th>\n",
       "      <td>411.0</td>\n",
       "      <td>2.412895e+01</td>\n",
       "      <td>9.108779e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.160000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count          mean           std           min  \\\n",
       "patient_id       2218.0  4.014678e+09  2.192419e+09  1.000000e+09   \n",
       "global_num       1314.0  4.664817e+03  2.874044e+03  1.000000e+00   \n",
       "age              1764.0  4.501134e+01  1.941264e+01  0.000000e+00   \n",
       "infection_order    42.0  2.285714e+00  1.254955e+00  1.000000e+00   \n",
       "infected_by       469.0  2.600789e+09  1.570638e+09  1.000000e+09   \n",
       "contact_number    411.0  2.412895e+01  9.108779e+01  0.000000e+00   \n",
       "\n",
       "                          25%           50%           75%           max  \n",
       "patient_id       1.700000e+09  6.001000e+09  6.004000e+09  7.000000e+09  \n",
       "global_num       1.908500e+03  5.210500e+03  7.481500e+03  8.717000e+03  \n",
       "age              2.700000e+01  4.550000e+01  5.800000e+01  1.040000e+02  \n",
       "infection_order  1.250000e+00  2.000000e+00  3.000000e+00  6.000000e+00  \n",
       "infected_by      1.200000e+09  2.000000e+09  4.100000e+09  6.113000e+09  \n",
       "contact_number   2.000000e+00  5.000000e+00  1.600000e+01  1.160000e+03  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['symptom_onset_date'] = pd.to_datetime(df['symptom_onset_date'])\n",
    "df['confirmed_date'] = pd.to_datetime(df['confirmed_date'])\n",
    "df['released_date'] = pd.to_datetime(df['released_date'])\n",
    "df['deceased_date'] = pd.to_datetime(df['deceased_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sex', 'country','province', 'city','infection_case', 'state']\n",
    "df[cols] = df[cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id                     int64\n",
       "global_num                   float64\n",
       "sex                         category\n",
       "age                          float64\n",
       "country                     category\n",
       "province                    category\n",
       "city                        category\n",
       "disease                       object\n",
       "infection_case              category\n",
       "infection_order              float64\n",
       "infected_by                  float64\n",
       "contact_number               float64\n",
       "symptom_onset_date    datetime64[ns]\n",
       "confirmed_date        datetime64[ns]\n",
       "released_date         datetime64[ns]\n",
       "deceased_date         datetime64[ns]\n",
       "state                       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id               0\n",
       "global_num             904\n",
       "sex                    145\n",
       "age                    454\n",
       "country                  0\n",
       "province                 0\n",
       "city                    65\n",
       "disease               2199\n",
       "infection_case        1055\n",
       "infection_order       2176\n",
       "infected_by           1749\n",
       "contact_number        1807\n",
       "symptom_onset_date    2025\n",
       "confirmed_date         141\n",
       "released_date         1995\n",
       "deceased_date         2186\n",
       "state                   88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state column in df has 88 missing values which depicts that those are missing apart from 'isolated','released' and'deceased. so we can replace NaN values as 'missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['released', 'isolated', 'deceased', NaN]\n",
       "Categories (3, object): ['released', 'isolated', 'deceased']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', 'female', NaN]\n",
       "Categories (2, object): ['male', 'female']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling Nan values in state as missing\n",
    "df['state'] = df['state'].cat.add_categories('missing').fillna('missing')\n",
    "df['sex'] = df['sex'].cat.add_categories('neutral').fillna('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['released', 'isolated', 'deceased', 'missing']\n",
       " Categories (4, object): ['released', 'isolated', 'deceased', 'missing'],\n",
       " ['male', 'female', 'neutral']\n",
       " Categories (3, object): ['male', 'female', 'neutral'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.unique(), df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4d2d4c58c7ac>:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['disease'].fillna(0, inplace=True)\n",
    "df.disease[df['disease']==True]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id               0\n",
       "global_num               0\n",
       "sex                      0\n",
       "age                      0\n",
       "country                  0\n",
       "province                 0\n",
       "city                    65\n",
       "disease                  0\n",
       "infection_case        1055\n",
       "infection_order          0\n",
       "infected_by              0\n",
       "contact_number           0\n",
       "symptom_onset_date    2025\n",
       "confirmed_date         141\n",
       "released_date         1995\n",
       "deceased_date         2186\n",
       "state                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isolated    1791\n",
       "released     307\n",
       "missing       88\n",
       "deceased      32\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state column indicates that 307 patients were released whereas there are 84 patients whose are released in released_dates columns are missing. These 84 NaT values are imputed with last patient released  date i.e 2020-03-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No of patients whose released dates missing are :', len(df[df['state']=='released'])- len(df[df['released_date'].notnull()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter those 84 missing values who are released but, released dates are missing\n",
    "filt = (df['released_date'].isin([pd.NaT]) & (df['state'] == 'released'))\n",
    "\n",
    "df.loc[filt, ['released_date']] = pd.to_datetime('2020-03-19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### symptom_onset_date are filled with confirmed_dates minus 2 days as is with most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1 = (df['symptom_onset_date'].isin([pd.NaT]) & (df['confirmed_date'] != pd.NaT))\n",
    "df.loc[filt1, ['symptom_onset_date','confirmed_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confirm_dates = df.loc[filt1, ['confirmed_date']]\n",
    "sub = confirm_dates - timedelta(days=2)\n",
    "df.loc[filt1, 'symptom_onset_date'] = sub.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filt1, 'symptom_onset_date'] = pd.to_datetime(df.loc[filt1, 'symptom_onset_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['symptom_onset_date'] = pd.to_datetime(df['symptom_onset_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['deceased_date'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[109,187],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index 109 and 187 have conflicting data, both rows have released dates and deceased dates and status of state is released. It is better to drop these rows to avoid conflicting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([109,187], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2 = (df['deceased_date'].isin([pd.NaT]) & (df['state'] == 'deceased'))\n",
    "df.loc[filt2, ['deceased_date','state']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing deceased_dates column who were declared dead in state column with end date of dataset i.e 2020-03-19 . Index No 1611 and 1946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filt2, 'deceased_date'] =  pd.to_datetime('2020-03-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['state']=='deceased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt3 = (df['symptom_onset_date'].isin([pd.NaT]) & df['confirmed_date'].isin([pd.NaT])& (df['state'] == 'deceased'))\n",
    "df.loc[filt3, ['symptom_onset_date','confirmed_date','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the symptom_onset_date and confirmed_date col of index with 1946 with next index date\n",
    "df.loc[filt3, ['symptom_onset_date']] = pd.to_datetime('2020-02-17')\n",
    "df.loc[filt3, ['confirmed_date']] = pd.to_datetime('2020-02-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt4 = (df['symptom_onset_date'].isin([pd.NaT]) & df['confirmed_date'].isin([pd.NaT])& (df['state'] =='isolated'))\n",
    "df.loc[filt4, ['symptom_onset_date','confirmed_date','state']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 140 isolated patients whose symptom_onset_date and confirmed_dates are missing. These  dates can be imputed by a date range between 19 Jan 2020 and 18 Mar 2020. As these 140 patients are still in isloation, imputing symptom_onset_date as 17 Mar 2020 and confirmed_dates  as 18 Mar 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['symptom_onset_date'].sort_values(ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['confirmed_date'] .sort_values(ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filt4, ['symptom_onset_date']] = pd.to_datetime('2020-03-17')\n",
    "df.loc[filt4, ['confirmed_date']] = pd.to_datetime('2020-03-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['infection_case'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns released_date and deceased_date contains null values which actually does not represent missing data but data that are not required. Deceased and Released date data is available in state column. Hence dropping released_date and deceased_date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['released_date','deceased_date'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDBxf5ZDB5ZZ"
   },
   "source": [
    "Review the count of unique values by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIdCkZ4AB5Zf"
   },
   "outputs": [],
   "source": [
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oENi5DRB5Zq"
   },
   "source": [
    "Review the percent of unique values by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IcO33VsB5Zt"
   },
   "outputs": [],
   "source": [
    "print(df.nunique()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCZHVugqB5Z4"
   },
   "source": [
    "Review the range of values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3zLsGxMB5Z5"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEBFq3hmB5aN"
   },
   "source": [
    "### Check for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9KGFCpkB5aP"
   },
   "outputs": [],
   "source": [
    "duplicateRowsDF = df[df.duplicated()]\n",
    "duplicateRowsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z_NuqkNSpOM"
   },
   "source": [
    "**<font color='teal'> Create dummy features for object type features. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd = pd.get_dummies(df.drop('state', axis=1),drop_first=True)\n",
    "dfd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WOrbEk1SpOH"
   },
   "source": [
    "Print the categorical columns and their associated levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QTm6RuRSpOH"
   },
   "outputs": [],
   "source": [
    "dfo = df.select_dtypes(exclude=['datetime', 'int64','float64'])\n",
    "dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get levels for all variables\n",
    "vn = pd.DataFrame(dfo.nunique()).reset_index()\n",
    "vn.columns = ['VarName', 'LevelsCount']\n",
    "vn.sort_values(by='LevelsCount', ascending =False)\n",
    "vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a43l6w_uSpOJ"
   },
   "source": [
    "**<font color='teal'> Plot the correlation heat map for the features.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRJlPqV5B5e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=25,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts of each variable value\n",
    "df.state.value_counts()\n",
    "\n",
    "#Rotate x-axis lables by 90 deg\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "#count plot for one variable\n",
    "sns.countplot(data = df, x = 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts of each variable value\n",
    "df.sex.value_counts()\n",
    "\n",
    "#Rotate x-axis lables by 90 deg\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "#count plot for one variable\n",
    "sns.countplot(data = df, x = 'sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdt = df.select_dtypes(exclude=('datetime', 'category'))\n",
    "dfdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(dfdt)\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(30, 30), sharey=True)\n",
    "\n",
    "sns.boxplot(data=dfdt, x='patient_id',ax=axes[0,0])\n",
    "sns.boxplot(data=dfdt, x='global_num', ax=axes[0,1])\n",
    "sns.boxplot(data=dfdt, x='age', ax=axes[1,0])\n",
    "sns.boxplot(data=dfdt, x='disease', ax=axes[1,1])\n",
    "sns.boxplot(data=dfdt, x='infection_order',whis=1, ax=axes[2,0])\n",
    "sns.boxplot(data=dfdt, x='infected_by', ax=axes[2,1])\n",
    "sns.boxplot(data=dfdt, x='contact_number', ax=axes[3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('state', axis =1).values\n",
    "y=df[['state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd['symptom_onset_date'] = dfd['symptom_onset_date'].astype('int64')\n",
    "dfd['confirmed_date'] = dfd['confirmed_date'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfd.values\n",
    "y = df[['state']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Hyperparametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 250],\n",
    "    'max_depth': [2, 4, 8, 16, 32, None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(n_estimators=250, max_depth=16,)\n",
    "model = best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict_proba(X_test)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = y_pred_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_roc_auc_ovo = roc_auc_score(y_test, y_pred_prob, multi_class=\"ovo\",\n",
    "                                  average=\"macro\")\n",
    "weighted_roc_auc_ovo = roc_auc_score(y_test, y_pred_prob, multi_class=\"ovo\",\n",
    "                                     average=\"weighted\")\n",
    "macro_roc_auc_ovr = roc_auc_score(y_test, y_pred_prob, multi_class=\"ovr\",\n",
    "                                  average=\"macro\")\n",
    "weighted_roc_auc_ovr = roc_auc_score(y_test, y_pred_prob, multi_class=\"ovr\",\n",
    "                                     average=\"weighted\")\n",
    "print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \" \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "print(\"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd0 = pd.get_dummies(df)\n",
    "dfd0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x = dfd.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error =[]\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i).fit(x)\n",
    "    kmeans.fit(x)\n",
    "    Error.append(kmeans.inertia_)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 11), Error)\n",
    "plt.title('Elbow method')\n",
    "plt.xlabel('No of clusters')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans3 = KMeans(n_clusters=4)\n",
    "labels = kmeans3.fit_predict(x)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0],x[:,1],c=labels, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYdW02QQSpOW"
   },
   "source": [
    "### Create Confusion Matrix Plots\n",
    "Confusion matrices are great ways to review your model performance for a multi-class classification problem. Being able to identify which class the misclassified observations end up in is a great way to determine if you need to build additional features to improve your overall model. In the example below we plot a regular counts confusion matrix as well as a weighted percent confusion matrix. The percent confusion matrix is particulary helpful when you have unbalanced class sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSWGVZU6SpOW"
   },
   "outputs": [],
   "source": [
    "class_names=['isolated','released','missing','deceased'] # name  of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjnV5ugJSpOb"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "#plt.savefig('figures/RF_cm_multi_class.png')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "#plt.savefig('figures/RF_cm_proportion_multi_class.png', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7PtbV4LSpOc"
   },
   "source": [
    "### Plot feature importances\n",
    "The random forest algorithm can be used as a regression or classification model. In either case it tends to be a bit of a black box, where understanding what's happening under the hood can be difficult. Plotting the feature importances is one way that you can gain a perspective on which features are driving the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1xpGOCVSpOc"
   },
   "outputs": [],
   "source": [
    "feature_importance = best_rf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ys_mI5GsSpOe"
   },
   "source": [
    "The popularity of random forest is primarily due to how well it performs in a multitude of data situations. It tends to handle highly correlated features well, where as a linear regression model would not. In this case study we demonstrate the performance ability even with only a few features and almost all of them being highly correlated with each other.\n",
    "Random Forest is also used as an efficient way to investigate the importance of a set of features with a large data set. Consider random forest to be one of your first choices when building a decision tree, especially for multiclass classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, roc, auc, logloss, pipeline, randomsearchcv, gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "FXGd_NbdB5kn"
   ],
   "name": "RandomForest_casestudy_covid19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
